{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c5bbc9",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Package Installation\n",
    "\n",
    "Run this cell to install all required packages with CUDA support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CUDA Environment Setup ==========\n",
    "# Run these commands in terminal before starting Jupyter:\n",
    "\n",
    "# 1. Create virtual environment\n",
    "# python3.11 -m venv niraakshan_cuda_env\n",
    "# source niraakshan_cuda_env/bin/activate\n",
    "\n",
    "# 2. Install CUDA-enabled packages\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "\n",
    "# Core packages\n",
    "!pip install opencv-contrib-python==4.8.1.78\n",
    "!pip install numpy==1.24.3\n",
    "!pip install Pillow==10.1.0\n",
    "\n",
    "# CUDA-accelerated face recognition\n",
    "# Install dlib with CUDA support (pre-built or compile from source)\n",
    "!pip install face-recognition==1.3.0\n",
    "# For CUDA-enabled dlib, compile from source:\n",
    "# git clone https://github.com/davisking/dlib.git\n",
    "# cd dlib\n",
    "# mkdir build && cd build\n",
    "# cmake .. -DDLIB_USE_CUDA=1 -DUSE_AVX_INSTRUCTIONS=1\n",
    "# cmake --build . --config Release\n",
    "# cd ..\n",
    "# python setup.py install\n",
    "\n",
    "# MediaPipe with GPU support\n",
    "!pip install mediapipe==0.10.8\n",
    "\n",
    "# TensorFlow with GPU support\n",
    "!pip install tensorflow[and-cuda]==2.15.0\n",
    "!pip install tensorflow-hub==0.15.0\n",
    "\n",
    "# CuPy for GPU array operations (match your CUDA version)\n",
    "# For CUDA 11.8:\n",
    "!pip install cupy-cuda11x==12.3.0\n",
    "# For CUDA 12.x:\n",
    "# !pip install cupy-cuda12x==12.3.0\n",
    "\n",
    "# Additional packages\n",
    "!pip install customtkinter==5.2.1\n",
    "!pip install pygame==2.5.2\n",
    "!pip install pydub==0.25.1\n",
    "!pip install psutil==5.9.6\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… Package installation complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f406da1",
   "metadata": {},
   "source": [
    "## 2. CUDA Environment Verification\n",
    "\n",
    "Verify that GPU is properly detected and CUDA is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30fdb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CUDA Environment Verification\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check Python version\n",
    "print(f\"\\nðŸ“Œ Python Version: {sys.version}\")\n",
    "\n",
    "# Check TensorFlow GPU\n",
    "print(f\"\\nðŸ“Œ TensorFlow Version: {tf.__version__}\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"âœ… GPU(s) Detected: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"   - {gpu}\")\n",
    "        # Get GPU details\n",
    "        gpu_details = tf.config.experimental.get_device_details(gpu)\n",
    "        print(f\"     Device Name: {gpu_details.get('device_name', 'Unknown')}\")\n",
    "    \n",
    "    # Test GPU computation\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "    print(f\"\\nâœ… GPU Computation Test: PASSED\")\n",
    "    print(f\"   Result: {c.numpy()}\")\n",
    "else:\n",
    "    print(\"âŒ No GPU detected! Running on CPU.\")\n",
    "    print(\"   Please install CUDA and cuDNN properly.\")\n",
    "\n",
    "# Check OpenCV CUDA support\n",
    "print(f\"\\nðŸ“Œ OpenCV Version: {cv2.__version__}\")\n",
    "if cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
    "    print(f\"âœ… OpenCV CUDA Support: Enabled\")\n",
    "    print(f\"   CUDA Devices: {cv2.cuda.getCudaEnabledDeviceCount()}\")\n",
    "else:\n",
    "    print(\"âš ï¸  OpenCV CUDA Support: Disabled (using CPU fallback)\")\n",
    "    print(\"   Tip: Install opencv-contrib-python with CUDA build for better performance\")\n",
    "\n",
    "# Check CuPy\n",
    "try:\n",
    "    import cupy as cp\n",
    "    print(f\"\\nðŸ“Œ CuPy Version: {cp.__version__}\")\n",
    "    print(f\"âœ… CuPy CUDA Support: Enabled\")\n",
    "    \n",
    "    # Test CuPy GPU computation\n",
    "    x_gpu = cp.array([1, 2, 3, 4, 5])\n",
    "    y_gpu = x_gpu * 2\n",
    "    print(f\"   CuPy Test: {y_gpu}\")\n",
    "except ImportError:\n",
    "    print(\"\\nâš ï¸  CuPy not installed. GPU array operations will use NumPy (CPU).\")\n",
    "\n",
    "# Check MediaPipe\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "    print(f\"\\nðŸ“Œ MediaPipe Version: {mp.__version__}\")\n",
    "    print(f\"âœ… MediaPipe Installed\")\n",
    "except ImportError:\n",
    "    print(\"\\nâŒ MediaPipe not installed!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Environment check complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5227e45",
   "metadata": {},
   "source": [
    "## 3. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries with GPU optimization settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== GPU Optimization Settings ==========\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduce TensorFlow logging\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'  # Dynamic GPU memory allocation\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use first GPU\n",
    "\n",
    "# OpenCV FFMPEG optimization for RTSP streams\n",
    "if \"OPENCV_FFMPEG_CAPTURE_OPTIONS\" not in os.environ:\n",
    "    os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;tcp|stimeout;5000000|video_codec;h264\"\n",
    "\n",
    "# ========== Core Imports ==========\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import face_recognition\n",
    "from PIL import Image, ImageTk\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import gc\n",
    "import psutil\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque, Counter\n",
    "from types import SimpleNamespace\n",
    "import threading\n",
    "import warnings\n",
    "\n",
    "# GPU array operations\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_ARRAY_LIB = cp\n",
    "    USE_CUPY = True\n",
    "    print(\"âœ… Using CuPy for GPU array operations\")\n",
    "except ImportError:\n",
    "    GPU_ARRAY_LIB = np\n",
    "    USE_CUPY = False\n",
    "    print(\"âš ï¸  CuPy not available, using NumPy (CPU fallback)\")\n",
    "\n",
    "# UI Libraries\n",
    "import tkinter as tk\n",
    "import customtkinter as ctk\n",
    "from tkinter import font, simpledialog, messagebox, filedialog\n",
    "\n",
    "# Audio libraries\n",
    "try:\n",
    "    import pygame\n",
    "    PYGAME_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYGAME_AVAILABLE = False\n",
    "    print(\"âš ï¸  pygame not available (audio alerts disabled)\")\n",
    "\n",
    "try:\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.playback import play\n",
    "    PYDUB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYDUB_AVAILABLE = False\n",
    "    print(\"âš ï¸  pydub not available (audio alerts disabled)\")\n",
    "\n",
    "# Set appearance\n",
    "ctk.set_appearance_mode(\"dark\")\n",
    "ctk.set_default_color_theme(\"blue\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "logging.getLogger('absl').setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "print(\"\\nâœ… All libraries imported successfully!\")\n",
    "print(f\"   - TensorFlow: {tf.__version__}\")\n",
    "print(f\"   - OpenCV: {cv2.__version__}\")\n",
    "print(f\"   - MediaPipe: {mp.__version__}\")\n",
    "print(f\"   - GPU Acceleration: {'âœ… ENABLED' if len(tf.config.list_physical_devices('GPU')) > 0 else 'âŒ DISABLED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f33d7f6",
   "metadata": {},
   "source": [
    "## 4. GPU-Optimized Configuration & Logging\n",
    "\n",
    "Configure GPU memory management and logging system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0707ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== GPU Memory Configuration ==========\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth (allocate memory as needed)\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        # Optional: Set memory limit (e.g., 4GB for GTX 1080 with 8GB VRAM)\n",
    "        # tf.config.set_logical_device_configuration(\n",
    "        #     gpus[0],\n",
    "        #     [tf.config.LogicalDeviceConfiguration(memory_limit=4096)]\n",
    "        # )\n",
    "        \n",
    "        print(f\"âœ… GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš ï¸  GPU configuration error: {e}\")\n",
    "\n",
    "# ========== Configuration Loading ==========\n",
    "def load_config():\n",
    "    \"\"\"Load configuration with GPU-optimized defaults\"\"\"\n",
    "    try:\n",
    "        config_path = \"config.json\"\n",
    "        if os.path.exists(config_path):\n",
    "            with open(config_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Config load error: {e}. Using GPU-optimized defaults.\")\n",
    "    \n",
    "    return {\n",
    "        \"detection\": {\n",
    "            \"min_detection_confidence\": 0.5,\n",
    "            \"min_tracking_confidence\": 0.5,\n",
    "            \"face_recognition_tolerance\": 0.5,\n",
    "            \"re_detect_interval\": 8,\n",
    "            \"use_gpu\": True  # âœ… GPU acceleration enabled\n",
    "        },\n",
    "        \"alert\": {\n",
    "            \"default_interval_seconds\": 10,\n",
    "            \"alert_cooldown_seconds\": 2.5\n",
    "        },\n",
    "        \"performance\": {\n",
    "            \"gui_refresh_ms\": 30,\n",
    "            \"pose_buffer_size\": 12,\n",
    "            \"frame_skip_interval\": 1,  # Lower for GPU (can process more frames)\n",
    "            \"enable_frame_skipping\": False,  # Disable with GPU\n",
    "            \"min_buffer_for_classification\": 5,\n",
    "            \"gpu_batch_size\": 4  # âœ… Process multiple frames in parallel\n",
    "        },\n",
    "        \"logging\": {\n",
    "            \"log_directory\": \"logs\",\n",
    "            \"max_log_size_mb\": 10,\n",
    "            \"auto_flush_interval\": 50\n",
    "        },\n",
    "        \"storage\": {\n",
    "            \"alert_snapshots_dir\": \"alert_snapshots\",\n",
    "            \"snapshot_retention_days\": 30,\n",
    "            \"guard_profiles_dir\": \"guard_profiles\",\n",
    "            \"capture_snapshots_dir\": \"capture_snapshots\",\n",
    "            \"audio_files_dir\": \"audio_files\"\n",
    "        },\n",
    "        \"monitoring\": {\n",
    "            \"mode\": \"pose\",\n",
    "            \"session_restart_prompt_hours\": 8\n",
    "        },\n",
    "        \"gpu\": {  # âœ… GPU-specific settings\n",
    "            \"device_id\": 0,\n",
    "            \"memory_fraction\": 0.8,  # Use 80% of GPU memory\n",
    "            \"allow_growth\": True,\n",
    "            \"use_tensorrt\": False  # Enable TensorRT optimization (requires conversion)\n",
    "        }\n",
    "    }\n",
    "\n",
    "CONFIG = load_config()\n",
    "\n",
    "# ========== Logging Setup ==========\n",
    "os.makedirs(CONFIG[\"logging\"][\"log_directory\"], exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger(\"à¤¨à¤¿à¤°à¤¾à¤•à¥à¤·à¤£_CUDA\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Console handler\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_formatter = logging.Formatter('%(asctime)s - [GPU] - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_formatter)\n",
    "\n",
    "# File handler\n",
    "file_handler = RotatingFileHandler(\n",
    "    os.path.join(CONFIG[\"logging\"][\"log_directory\"], \"session_cuda.log\"),\n",
    "    maxBytes=CONFIG[\"logging\"][\"max_log_size_mb\"] * 1024 * 1024,\n",
    "    backupCount=5\n",
    ")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_formatter = logging.Formatter('%(asctime)s - [GPU] - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# ========== Create Required Directories ==========\n",
    "for key in [\"alert_snapshots_dir\", \"guard_profiles_dir\", \"capture_snapshots_dir\", \"audio_files_dir\"]:\n",
    "    dir_path = CONFIG[\"storage\"][key]\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# ========== CSV Log File ==========\n",
    "csv_file = os.path.join(CONFIG[\"logging\"][\"log_directory\"], \"events.csv\")\n",
    "if not os.path.exists(csv_file):\n",
    "    with open(csv_file, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Timestamp\", \"Name\", \"Action\", \"Status\", \"Image_Path\", \"Confidence\", \"GPU_Utilized\"])\n",
    "\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(\"à¤¨à¤¿à¤°à¤¾à¤•à¥à¤·à¤£ CUDA System Initialized\")\n",
    "logger.info(f\"GPU: {'âœ… ENABLED' if CONFIG['detection']['use_gpu'] else 'âŒ DISABLED'}\")\n",
    "logger.info(f\"TensorFlow GPU Devices: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "print(\"\\nâœ… Configuration and logging initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952baf00",
   "metadata": {},
   "source": [
    "## 5. GPU-Accelerated Helper Functions\n",
    "\n",
    "Utility functions optimized for GPU processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcffe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== GPU Memory Management ==========\n",
    "def optimize_gpu_memory():\n",
    "    \"\"\"Optimize GPU memory usage with aggressive garbage collection\"\"\"\n",
    "    try:\n",
    "        # Clear Python garbage\n",
    "        gc.collect()\n",
    "        \n",
    "        # Clear TensorFlow GPU memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        # Clear CuPy memory pool if available\n",
    "        if USE_CUPY:\n",
    "            mempool = cp.get_default_memory_pool()\n",
    "            pinned_mempool = cp.get_default_pinned_memory_pool()\n",
    "            mempool.free_all_blocks()\n",
    "            pinned_mempool.free_all_blocks()\n",
    "        \n",
    "        logger.debug(\"GPU memory optimized\")\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"GPU memory optimization error: {e}\")\n",
    "\n",
    "def get_gpu_memory_info():\n",
    "    \"\"\"Get current GPU memory usage\"\"\"\n",
    "    try:\n",
    "        if USE_CUPY:\n",
    "            mempool = cp.get_default_memory_pool()\n",
    "            used = mempool.used_bytes() / (1024**2)  # MB\n",
    "            total = mempool.total_bytes() / (1024**2)  # MB\n",
    "            return {\"used_mb\": used, \"total_mb\": total, \"utilization\": (used/total*100) if total > 0 else 0}\n",
    "        else:\n",
    "            return {\"used_mb\": 0, \"total_mb\": 0, \"utilization\": 0}\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"GPU memory info error: {e}\")\n",
    "        return {\"used_mb\": 0, \"total_mb\": 0, \"utilization\": 0}\n",
    "\n",
    "# ========== GPU-Accelerated Image Processing ==========\n",
    "def gpu_resize_frame(frame, target_size, use_gpu=True):\n",
    "    \"\"\"Resize frame using GPU if available\"\"\"\n",
    "    if use_gpu and cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
    "        try:\n",
    "            # Upload to GPU\n",
    "            gpu_frame = cv2.cuda_GpuMat()\n",
    "            gpu_frame.upload(frame)\n",
    "            \n",
    "            # Resize on GPU\n",
    "            gpu_resized = cv2.cuda.resize(gpu_frame, target_size)\n",
    "            \n",
    "            # Download from GPU\n",
    "            return gpu_resized.download()\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"GPU resize failed, using CPU: {e}\")\n",
    "    \n",
    "    # CPU fallback\n",
    "    return cv2.resize(frame, target_size)\n",
    "\n",
    "def gpu_cvtColor(frame, conversion_code, use_gpu=True):\n",
    "    \"\"\"Convert color space using GPU if available\"\"\"\n",
    "    if use_gpu and cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
    "        try:\n",
    "            gpu_frame = cv2.cuda_GpuMat()\n",
    "            gpu_frame.upload(frame)\n",
    "            gpu_converted = cv2.cuda.cvtColor(gpu_frame, conversion_code)\n",
    "            return gpu_converted.download()\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"GPU cvtColor failed, using CPU: {e}\")\n",
    "    \n",
    "    return cv2.cvtColor(frame, conversion_code)\n",
    "\n",
    "def gpu_apply_clahe(frame, use_gpu=True):\n",
    "    \"\"\"Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) using GPU\"\"\"\n",
    "    if use_gpu and cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
    "        try:\n",
    "            # Convert to LAB color space\n",
    "            lab = gpu_cvtColor(frame, cv2.COLOR_BGR2LAB, use_gpu=True)\n",
    "            l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "            \n",
    "            # Upload L channel to GPU\n",
    "            gpu_l = cv2.cuda_GpuMat()\n",
    "            gpu_l.upload(l_channel)\n",
    "            \n",
    "            # Apply CLAHE on GPU\n",
    "            clahe = cv2.cuda.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "            gpu_l_clahe = clahe.apply(gpu_l, cv2.cuda_Stream.Null())\n",
    "            \n",
    "            # Download result\n",
    "            l_clahe = gpu_l_clahe.download()\n",
    "            \n",
    "            # Merge back\n",
    "            lab_clahe = cv2.merge([l_clahe, a_channel, b_channel])\n",
    "            return gpu_cvtColor(lab_clahe, cv2.COLOR_LAB2BGR, use_gpu=True)\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"GPU CLAHE failed, using CPU: {e}\")\n",
    "    \n",
    "    # CPU fallback\n",
    "    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l_channel)\n",
    "    lab_clahe = cv2.merge([l_clahe, a_channel, b_channel])\n",
    "    return cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# ========== File Storage Utilities ==========\n",
    "def get_storage_paths():\n",
    "    \"\"\"Get organized storage directory paths\"\"\"\n",
    "    paths = {\n",
    "        \"guard_profiles\": CONFIG[\"storage\"][\"guard_profiles_dir\"],\n",
    "        \"capture_snapshots\": CONFIG[\"storage\"][\"capture_snapshots_dir\"],\n",
    "        \"logs\": CONFIG[\"logging\"][\"log_directory\"],\n",
    "        \"alert_snapshots\": CONFIG[\"storage\"][\"alert_snapshots_dir\"]\n",
    "    }\n",
    "    \n",
    "    for path in paths.values():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def save_guard_face(face_image, guard_name, angle=\"front\"):\n",
    "    \"\"\"Save guard face image\"\"\"\n",
    "    paths = get_storage_paths()\n",
    "    safe_name = guard_name.strip().replace(\" \", \"_\")\n",
    "    \n",
    "    if angle and angle != \"front\":\n",
    "        guard_dir = os.path.join(paths[\"guard_profiles\"], f\"target_{safe_name}\")\n",
    "        os.makedirs(guard_dir, exist_ok=True)\n",
    "        profile_path = os.path.join(guard_dir, f\"{angle}.jpg\")\n",
    "    else:\n",
    "        profile_path = os.path.join(paths[\"guard_profiles\"], f\"target_{safe_name}_face.jpg\")\n",
    "        guard_dir = os.path.join(paths[\"guard_profiles\"], f\"target_{safe_name}\")\n",
    "        os.makedirs(guard_dir, exist_ok=True)\n",
    "        front_path = os.path.join(guard_dir, \"front.jpg\")\n",
    "        cv2.imwrite(front_path, face_image)\n",
    "    \n",
    "    cv2.imwrite(profile_path, face_image)\n",
    "    logger.info(f\"Saved guard face ({angle}): {profile_path}\")\n",
    "    return profile_path\n",
    "\n",
    "def cleanup_old_snapshots():\n",
    "    \"\"\"Cleanup old alert snapshots\"\"\"\n",
    "    try:\n",
    "        retention_days = CONFIG[\"storage\"][\"snapshot_retention_days\"]\n",
    "        cutoff_time = datetime.now() - timedelta(days=retention_days)\n",
    "        snapshot_dir = CONFIG[\"storage\"][\"alert_snapshots_dir\"]\n",
    "        \n",
    "        for filename in os.listdir(snapshot_dir):\n",
    "            filepath = os.path.join(snapshot_dir, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                file_time = datetime.fromtimestamp(os.path.getmtime(filepath))\n",
    "                if file_time < cutoff_time:\n",
    "                    os.remove(filepath)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Snapshot cleanup error: {e}\")\n",
    "\n",
    "# Start cleanup thread\n",
    "threading.Thread(target=cleanup_old_snapshots, daemon=True).start()\n",
    "\n",
    "print(\"\\nâœ… GPU-optimized helper functions loaded!\")\n",
    "print(f\"   - GPU Resize: {'âœ… Available' if cv2.cuda.getCudaEnabledDeviceCount() > 0 else 'âŒ Not Available'}\")\n",
    "print(f\"   - GPU CLAHE: {'âœ… Available' if cv2.cuda.getCudaEnabledDeviceCount() > 0 else 'âŒ Not Available'}\")\n",
    "print(f\"   - CuPy Arrays: {'âœ… Enabled' if USE_CUPY else 'âŒ Disabled'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebd880",
   "metadata": {},
   "source": [
    "## 6. GPU-Accelerated Face Detection & Recognition\n",
    "\n",
    "Face detection and recognition with CUDA acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== GPU-Accelerated Face Detection ==========\n",
    "def detect_faces_gpu(rgb_frame, model=\"hog\", use_gpu=True):\n",
    "    \"\"\"\n",
    "    Detect faces using GPU-accelerated face_recognition library.\n",
    "    \n",
    "    Note: face_recognition with dlib compiled with CUDA support will automatically\n",
    "    use GPU for HOG-based detection. For CNN model, GPU is always used if available.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # face_recognition will use GPU if dlib was compiled with CUDA\n",
    "        if use_gpu and model == \"cnn\":\n",
    "            # CNN model is always GPU-accelerated if CUDA is available\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=\"cnn\")\n",
    "        else:\n",
    "            # HOG model (faster, uses GPU if dlib has CUDA support)\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=\"hog\")\n",
    "        \n",
    "        return face_locations\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Face detection error: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_face_encodings_gpu(rgb_frame, face_locations, num_jitters=1):\n",
    "    \"\"\"\n",
    "    Generate face encodings using GPU if available.\n",
    "    \n",
    "    face_recognition will use GPU for encoding if dlib was compiled with CUDA.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # face_recognition will automatically use GPU if available\n",
    "        encodings = face_recognition.face_encodings(\n",
    "            rgb_frame, \n",
    "            known_face_locations=face_locations,\n",
    "            num_jitters=num_jitters\n",
    "        )\n",
    "        return encodings\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Face encoding error: {e}\")\n",
    "        return []\n",
    "\n",
    "def compare_faces_gpu(known_encodings, face_encoding, tolerance=0.6):\n",
    "    \"\"\"\n",
    "    Compare face encodings using GPU-accelerated distance calculation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if USE_CUPY and len(known_encodings) > 0:\n",
    "            # Convert to CuPy arrays for GPU computation\n",
    "            known_arr = cp.array(known_encodings)\n",
    "            face_arr = cp.array(face_encoding)\n",
    "            \n",
    "            # Compute Euclidean distances on GPU\n",
    "            distances = cp.linalg.norm(known_arr - face_arr, axis=1)\n",
    "            \n",
    "            # Convert back to CPU for comparison\n",
    "            matches = distances.get() <= tolerance\n",
    "            return matches.tolist()\n",
    "        else:\n",
    "            # CPU fallback using face_recognition\n",
    "            return face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Face comparison error: {e}\")\n",
    "        return [False] * len(known_encodings)\n",
    "\n",
    "def face_distance_gpu(face_encodings, face_to_compare):\n",
    "    \"\"\"\n",
    "    Calculate face distances using GPU.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if USE_CUPY and len(face_encodings) > 0:\n",
    "            encodings_arr = cp.array(face_encodings)\n",
    "            compare_arr = cp.array(face_to_compare)\n",
    "            distances = cp.linalg.norm(encodings_arr - compare_arr, axis=1)\n",
    "            return distances.get()\n",
    "        else:\n",
    "            return face_recognition.face_distance(face_encodings, face_to_compare)\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Face distance error: {e}\")\n",
    "        return np.array([1.0] * len(face_encodings))\n",
    "\n",
    "# Test GPU face detection\n",
    "print(\"\\nâœ… GPU-accelerated face detection functions loaded!\")\n",
    "print(\"   Testing face detection capabilities...\")\n",
    "\n",
    "# Create a dummy test image\n",
    "test_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "test_rgb = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Test face detection (should return empty list for random image)\n",
    "start_time = time.time()\n",
    "faces = detect_faces_gpu(test_rgb, model=\"hog\", use_gpu=True)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"   Face detection test: {elapsed*1000:.2f}ms\")\n",
    "print(f\"   Detected faces: {len(faces)} (expected 0 for random image)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc1404",
   "metadata": {},
   "source": [
    "## 7. GPU-Accelerated Pose Estimation\n",
    "\n",
    "MediaPipe Pose with GPU backend for real-time pose tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Initialize MediaPipe Pose with GPU ==========\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Initialize pose detector with GPU delegate\n",
    "pose_detector_gpu = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,  # 0=Lite, 1=Full, 2=Heavy\n",
    "    smooth_landmarks=True,\n",
    "    enable_segmentation=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "logger.info(\"MediaPipe Pose initialized with GPU backend\")\n",
    "\n",
    "# ========== Pose Classification Function ==========\n",
    "def classify_action(landmarks, h, w):\n",
    "    \"\"\"\n",
    "    Classify pose action from MediaPipe landmarks.\n",
    "    Supports: Hands Up, Hands Crossed, One Hand Raised, T-Pose, Sit, Standing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        NOSE = mp_holistic.PoseLandmark.NOSE.value\n",
    "        L_WRIST = mp_holistic.PoseLandmark.LEFT_WRIST.value\n",
    "        R_WRIST = mp_holistic.PoseLandmark.RIGHT_WRIST.value\n",
    "        L_ELBOW = mp_holistic.PoseLandmark.LEFT_ELBOW.value\n",
    "        R_ELBOW = mp_holistic.PoseLandmark.RIGHT_ELBOW.value\n",
    "        L_SHOULDER = mp_holistic.PoseLandmark.LEFT_SHOULDER.value\n",
    "        R_SHOULDER = mp_holistic.PoseLandmark.RIGHT_SHOULDER.value\n",
    "        L_HIP = mp_holistic.PoseLandmark.LEFT_HIP.value\n",
    "        R_HIP = mp_holistic.PoseLandmark.RIGHT_HIP.value\n",
    "        L_KNEE = mp_holistic.PoseLandmark.LEFT_KNEE.value\n",
    "        R_KNEE = mp_holistic.PoseLandmark.RIGHT_KNEE.value\n",
    "\n",
    "        nose = landmarks[NOSE]\n",
    "        l_wrist = landmarks[L_WRIST]\n",
    "        r_wrist = landmarks[R_WRIST]\n",
    "        l_shoulder = landmarks[L_SHOULDER]\n",
    "        r_shoulder = landmarks[R_SHOULDER]\n",
    "        l_hip = landmarks[L_HIP]\n",
    "        r_hip = landmarks[R_HIP]\n",
    "        l_knee = landmarks[L_KNEE]\n",
    "        r_knee = landmarks[R_KNEE]\n",
    "\n",
    "        # Calculate body scale for distance-agnostic detection\n",
    "        shoulder_to_hip_dist = abs(l_shoulder.y - l_hip.y)\n",
    "        if shoulder_to_hip_dist < 0.01:\n",
    "            return \"Standing\"\n",
    "        \n",
    "        # Threshold multipliers based on body size\n",
    "        HANDS_UP_THRESHOLD = shoulder_to_hip_dist * 0.4\n",
    "        HANDS_CROSSED_TOLERANCE = shoulder_to_hip_dist * 0.3\n",
    "        \n",
    "        # Check visibility\n",
    "        l_wrist_visible = l_wrist.visibility > 0.45\n",
    "        r_wrist_visible = r_wrist.visibility > 0.45\n",
    "        nose_visible = nose.visibility > 0.40\n",
    "        \n",
    "        # Hands Up Detection\n",
    "        if l_wrist_visible and r_wrist_visible and nose_visible:\n",
    "            wrist_above_nose_l = (nose.y - l_wrist.y) > (HANDS_UP_THRESHOLD * 0.8)\n",
    "            wrist_above_nose_r = (nose.y - r_wrist.y) > (HANDS_UP_THRESHOLD * 0.8)\n",
    "            \n",
    "            if wrist_above_nose_l and wrist_above_nose_r:\n",
    "                return \"Hands Up\"\n",
    "        \n",
    "        # One Hand Raised Detection\n",
    "        if l_wrist_visible and r_wrist_visible:\n",
    "            chest_y = (l_shoulder.y + r_shoulder.y) / 2\n",
    "            \n",
    "            left_raised = (nose.y - l_wrist.y) > (HANDS_UP_THRESHOLD * 0.8)\n",
    "            right_down = (r_wrist.y - chest_y) > (HANDS_CROSSED_TOLERANCE * 0.8)\n",
    "            \n",
    "            if left_raised and right_down:\n",
    "                return \"One Hand Raised (Left)\"\n",
    "            \n",
    "            right_raised = (nose.y - r_wrist.y) > (HANDS_UP_THRESHOLD * 0.8)\n",
    "            left_down = (l_wrist.y - chest_y) > (HANDS_CROSSED_TOLERANCE * 0.8)\n",
    "            \n",
    "            if right_raised and left_down:\n",
    "                return \"One Hand Raised (Right)\"\n",
    "        \n",
    "        # Sit/Stand Detection\n",
    "        if l_knee.visibility > 0.30 and r_knee.visibility > 0.30:\n",
    "            thigh_angle_l = abs(l_knee.y - l_hip.y)\n",
    "            thigh_angle_r = abs(r_knee.y - r_hip.y)\n",
    "            avg_thigh_angle = (thigh_angle_l + thigh_angle_r) / 2\n",
    "            \n",
    "            sit_threshold = shoulder_to_hip_dist * 0.15\n",
    "            \n",
    "            if avg_thigh_angle < sit_threshold:\n",
    "                return \"Sit\"\n",
    "            else:\n",
    "                return \"Standing\"\n",
    "        \n",
    "        return \"Standing\"\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Pose classification error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "def process_pose_gpu(frame, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Process frame for pose detection using GPU.\n",
    "    Returns pose landmarks and action classification.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert BGR to RGB\n",
    "        rgb_frame = gpu_cvtColor(frame, cv2.COLOR_BGR2RGB, use_gpu=use_gpu)\n",
    "        \n",
    "        # Process with MediaPipe (automatically uses GPU if available)\n",
    "        results = pose_detector_gpu.process(rgb_frame)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            h, w, _ = frame.shape\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Classify action\n",
    "            action = classify_action(landmarks, h, w)\n",
    "            \n",
    "            return {\n",
    "                \"landmarks\": landmarks,\n",
    "                \"action\": action,\n",
    "                \"confidence\": np.mean([lm.visibility for lm in landmarks]),\n",
    "                \"pose_world_landmarks\": results.pose_world_landmarks\n",
    "            }\n",
    "        \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Pose processing error: {e}\")\n",
    "        return None\n",
    "\n",
    "def draw_pose_landmarks_gpu(frame, pose_result):\n",
    "    \"\"\"\n",
    "    Draw pose landmarks on frame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pose_result and pose_result.get(\"landmarks\"):\n",
    "            # Create pose landmarks object for drawing\n",
    "            landmarks_proto = mp_pose.PoseLandmark()\n",
    "            for landmark in pose_result[\"landmarks\"]:\n",
    "                landmarks_proto.landmark.add().CopyFrom(landmark)\n",
    "            \n",
    "            # Draw landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                landmarks_proto,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Draw landmarks error: {e}\")\n",
    "\n",
    "print(\"\\nâœ… GPU-accelerated pose estimation loaded!\")\n",
    "print(\"   MediaPipe Pose initialized with GPU backend\")\n",
    "\n",
    "# Test pose detection\n",
    "test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "start_time = time.time()\n",
    "pose_result = process_pose_gpu(test_frame, use_gpu=True)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"   Pose detection test: {elapsed*1000:.2f}ms\")\n",
    "print(f\"   Result: {pose_result is not None}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
